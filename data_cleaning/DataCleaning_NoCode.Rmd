---
title: "Getting your data ready for analysis"
author: "Ellen Tedeschi"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 5
---
## Goals of this lesson

Students will learn:
1. How to open various data types in R
2. How to check for missing or problematic data and address issues.
3. How to rearrange and shape data in preparation for analysis. 

## Getting your Data into R

### Entering data directly

In some cases, you may want to enter data directly into R. This is easy with a small number of cases.

```{r}

# Direct Data Entry


```


### Reading data into R

It's also easy to introduce errors this way, and with a lot of data it would get tedious. Most of the time, you'll be reading data from an external file (.txt of .csv), or opening up an existing dataset in R. Once you find the location of your files, what you do next will depend on the file format.

#### What's your working directory and where is the file you want?
```{r}



```

#### What kind of file do you have?
```{r}

## For .txt, .csv and tab-deliminated files



# Try this one, and then look at the data



# Add arguments to help R figure out how your data is organized




# Other options include:
# read.csv, just like read.table but with better defaults for .csv
# read.delim, for when you have a separator that's not standard

## For getting data that's already in R-format



## For getting data from another program:
#install.packages("foreign")
#library(foreign)

#read.spss("<Path to file>")
#read.dta("<Path to file>")

```

Remember, all of these commands can have arguments that will help R make sense of your data. To find out what arguments are possible, put a question mark in front of the name of the function (e.g. ?read.table). For options not listed here, Google "<your data type> into R" and you should find instructions.

## Inspecting your data

Now you have data, time to get some results! But wait! Are you sure this data is ok? Doing some basic steps to inspect your data now can save you lots of headaches later, and R makes it really easy.

Start by checking that you have the expected number of rows and columns in your data frame. You can do this by looking at the Environment window, or by asking R.

### How is your data frame structured?
```{r}

# Number of rows and number of columns


# Names of columns


# look at the first few rows


```

### Rename a variable

Ok, looks good. But what is that fifth variable? What does that even mean? Luckily, this is your study and you know that it's a personality questionnaire measuring neuroticism. Let's fix that.

```{r}

# Change a varialbe name

```

### Check for missing data

On problem you may have is missing data. Sometimes this is something you already know about, but you should check your data frame anyway to make sure nothing got missed in a data entry error. For small datasets, you can do this visually, but for larger ones you can ask R.

```{r}

# This command asks for rows that are not complete. 


```

In this case, the missing value is the Age value in row 39. You know you have this info somewhere on a paper form, so you go dig it up and want to replace it.

```{r}

# Directly replace a missing value


```

### Check for correct values

To look at some of the other variables, let's use the table function. This works well for factors or variables with only a few different values. Our condition and sex variables are good here.
```{r}

# Make tables of categorical variables


```

When we look at the table for the Sex variable, we see another data entry problem. We have a third category that should really be another case of "Female".We can fix all of these at once, but sometimes messing with factors is more complicated than numeric variables.

```{r}

# Replace bad category label


```

Now let's look at the continuous variables. You can also look at these with the table function, but sometimes it's easier to visualize. The histogram function is good here.

```{r}
# Create histograms to see data distribution



```

Looks like we have a potential outlier on the neuroticism score. This could be an entry error, but it could also be a real value that just happens to be really low. This is why data inspection is so important for later analysis - now you know that value is there, it's up to you to decide how to deal with it.

## Getting ready for analysis

Now that we've gone through and cleaned up the problems, you can think ahead to how you'll want to use this data. 

### Recoding variables

Sometimes we want to treat categorical variables as factors, but sometimes we want to pretend they're numeric (as in a regression, when binary variables can be coded as 0 and 1). Right now, Condition is coded as a binary numeric variable, but that's not very informative, so you'd rather have the values be descriptive. Here, the function mapvalues from the plyr package is really useful. We'll create a second variable instead of overwriting Condition

```{r}

library(plyr)
# Transform into factor with labels


```

### Calculating new variables

You may also want to recalculate or rescale some variables. For example, we can turn Neuroticism into a Z score, or calculate an average response across the four time points. For Z scores, you can use the scale() function. You can also use this to just mean-center the data.

```{r}

# calculate Z scores


# one way to average multiple columns


```

### Shaping data

Finally, you may want to change the layout of your data. Right now, our data frame is in "wide" format, which means that each row is a subject, and each observation gets its own column. For some analyses, you'll need to use "long" format, where each row is an observation, and columns specify things like time and ID to differentiate the observations. There are lots of packages that can handle data reshaping, but I'll show the gather and spread functions from tidyr

```{r}

library(tidyr)
# Key is the name for the new column that will identify which observation it is, and value is the name for the new column that will have the actual values in it. In theory, you can name these whatever you want, but to keep everyone on the same page, name the key "Time" and the value "Score".

# Spread lets you go back the other direction. This should be identical to the original mydata 

```

## Saving your work

Once you've created a data cleaning script like this one, you'll have a record of all the edits you've made on the raw data, and you can recreate your cleaned data just by running the script again. However, it's often easier to save your cleaned data as its own file **(never overwrite the raw data)**, so when you come back to do analysis you don't have to bother with all the cleaning steps. 

You can always save data frames as a .csv for easy sharing and viewing outside of R.

```{r}

# Write data to a .csv

```

However, you can also save in an R format that lets you save multiple variables/objects in the same file. For example, you might want to have a long and wide format, or one dataframe with all the data and one with just subject information. Saving as a .rda file allows you to save multiple objects at once for easy loading into R. You can also have the outputs of statistical models saved in these, along with their data.

```{r}

# Save a .rda. Add as many objects as you want, separated by commas


```

## Data Challenge!

Go to the file "CleaningChallenge_NoCode.Rmd" for your data challenge. This challenge will include skills from this tutorial, but it will also ask you to explore new functions we didn't cover. Remember to use the help command in R (?<function name>) and google as necessary. You'll also be using three files from "Study 2", so make sure they're in your folder: README_Study2.txt, Study2_Subjects.csv, and Study2_Trials.csv.

## Future Directions

Congratulations! You've now cleaned some data in R and you're ready to start the real analysis. This tutorial only went over some basic cleaning steps, as you work with your own data, you may find yourself needing other tools. We used functions that come with the basic level of R, but there are many specialized packages that can be used for cleaning and manipulating data structures.

