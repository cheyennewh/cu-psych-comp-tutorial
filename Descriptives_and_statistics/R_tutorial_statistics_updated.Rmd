---
title: "R_TUTORIAL_DESCRIPTIVES"
output: 
  html_document: 
    toc: true
    toc_float: true
--- 

# Welcome to the tutorial on statistics in R! 
Goals: 
1. Learn how to run simple statistical tests in R 
2. Learn how to visualize  the results of the models

# First things first:
let's open some packages we need for this tutorial.
```{r, include = F}
install.packages("effects")
#Effect Displays for Linear, Generalized Linear, and Other Models
#https://cran.r-project.org/web/packages/effects/effects.pdf

library(car)
library(effects)

```

# Next, let's get some data. We will use the multitasking dataset:
```{r}
# this dataset examines the relationship between multitasking and working memory.  original paper by Uncapher et al. 2016:  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4733435/pdf/nihms712443.pdf

df <- read.csv("uncapher_thieu_wagner_2016_target_memory.csv")

# let's refresh our memory on the variables in this dataset
names(df) 

# how many subjects are in this dataframe?
Nsubs <- length(unique(df$subjNum))

# for the sake of simplicity, let's consider only one condition of the experiment.
#(so it's not repeated measures)
df <- subset(df, numDist == 6 & conf == "hi" & !is.na(dprime))

# let's make a separate dataset that only includes high and low group status
df2 <- subset(df, numDist == 6 & conf == "hi" & !is.na(dprime)
             & groupStatus != "")
nrow(df2)

# let's re-factor this to remove the empty level. 
df2$groupStatus <- as.factor(df$groupStatus)

```

#1. Correlations
Correlations are as simple as it gets in R. Use the cor() function with your two variables to get the correlation coefficient. or use the cor.test() function to get the t, df, and p-value associated with your correlaton coefficient. 
Yesterday we plotted the relationship between multitasking and impulsivity; now let's test it!
```{r}
cor(df$bis, df$mmi)
cor.test(df$bis, df$mmi)
```

# 2. T-tests
First, let's check that our variance is not heterogenous between the two groups. We can do this by calling the leveneTest() function, which performs the Levene's test of Equality of Variances.
```{r}
# this functionis from the car package
leveneTest(df$bis, df$groupStatus) # we do not reject the null
```

Next, let's run the actual t-test using the t.test() function. The first argument is the y variable, followed by the grouping variable. R's default for t-test is a welch two-sample t-test, which assumes heterogenous variance between groups. 
```{r}

df2$groupStatus <- as.factor(ifelse(df2$groupStatus== "hi", "hi", "low"))
summary(df$groupStatus)
t.test(df$bis ~ df$groupStatus)
```
In the case you want to use a 'Students' t-test (SPSS default, asumes homogenous variances) you can specify that with the argument var.equal=TRUE.There are many other options here, including a paired samples t-test (more on that in the data challenge!)
```{r}
t.test(df2$bis~ df2$groupStatus, var.equal=TRUE)
#t = 1.2397, df = 66, p-value = 0.2195
```

#3. Anova 
A word of caution using statistics in R: there are many ways to run each statistical test. For an ANOVA, there are several didfferent packages that have different ways of running the ANOVA 'under the hood', or just use different conventions in reporting the results. To start with, we will show you how to run simple one-way and two-way anovas.

one -way anova. Does multitasking predict ADHD symptoms?

```{r}
aov_1 <- aov(adhd ~ groupStatus, data = df )
summary(aov_1) # anova output
coefficients(aov_1) # coefficients (betas) identical to t-test
```


Two way anova. Does  impulsivity interact with multitasking to predict ADHD symptoms?
```{r}

# next, let's make another factor, ADHD grouping, using mean split.
#df$adoups<- as.factor(ifelse(df$bis >= mean(df$bis, "hi", "low"))
df2$bis.groups <- as.factor(ifelse(df2$bis >= mean(df2$bis), "hi", "low"))
summary(df2$bis.groups)


aov_2 <- aov(adhd ~ groupStatus*bis.groups, data =df2)
summary(aov_2)
coefficients(aov_2)

# the "effect" package allows you to quickly view the fits of your model
plot(allEffects(aov_2))


# note:Effect package will not show you the original data, only fits. 
# note: we recommend using ggplot, but this is helpful for quick plotting.
```

Post-hoc comparisons for 2x2 anova. Again, note there are many options for posthoc tests depending on the assumptions of your data. Here we will learn Tukey's post-hoc, which is commonly used in the ANOVA framework in psychology. We will get the post-hoc contrasts for each level of the interaction using the function TukeyHSD(). The argument for the function is the model, whch we just created above.
```{r}
post_hoc <- TukeyHSD(aov_2)

post_hoc
```

We can now look at the 6 contrasts of the 2x2 interaction by indexing the results of the TukeyHSD() function.
```{r}
ph_table <- post_hoc$'groupStatus:bisGroups'
  
ph_table
```
# 4. linear regression 
Linear regression follow this formula: lm( y ~ x, data) where lm() is the function of the linear model. We will use the summary() function, with our model as input, to easly view a table of the results of the model.

Let's use the continuous variable for multitasking to predict individual differences in impulsivity 
```{r}

model1 <- lm(adhd~ mmi, data = df )

summary(model1)
```

The effect package provides a simple way to visualize the results of your model. we can quicky plot the linear regression slope with a 95% confidence interval. 
```{r}
plot(effect("mmi", model1))

# Like many R functions, there are many addtional arguments that will allow you to customize the plot and make it prettier. 
plot(effect("mmi", model1), main = "", xlab = "media multitasking", ylab ="ADHD symptoms", rug=FALSE)
```

# 5. Multiple regression using lm ()
 Let's estimate the effect of weight on mpg, controlling for displacement and transmission. We will use the lm() function again. 
What is the effect of mmi on impulsivity, controlling for ADHD?
Actually, looks like ADHD has a WAY stronger effect. 
```{r}
#lm( y ~ x + m + z, data)
model2 <- lm(adhd~ mmi + bis, data = df )
summary(model2) #we can see that both variables predict adhd symptoms quite strongly!
```

The effect package also allows you to plot the model fits for each coefficient, each controlling for all other variables in the model.
```{r}
plot(allEffects(model2))

```


# 6. interactions with continuous x continous variables
These can be fun but also tricky in R. First, let's visualize how two continuous variables might interact. We will use the coplot() function where: y ~ x | m
```{R}
coplot(adhd ~ bis | groupStatus , data = df2,number = 3,
       col = "black", bg = "blue", pch = 21) 
```

Next, let's run the linear model using lm (). The * indicates an interaction, where R will include the individual coefficienets for each variable automatically.
```{r}
c
model4 <- lm(adhd ~ mmi * bis, data =df )
summary(model4) 

```

The effect plot automatically choses specific levels of the variables to display your interactions. 
```{r}
plot(effect("mmi:bis", model4), rug = F, main = "", ylab= "ADHD symptoms", xlab = "Media Multitasking")

# the relationship between mmi and adhd is stronger when BIS is low.
```

You can also just plot the linesin a single plot (without CI) using the multiline=T option. 
```{r}
plot(effect("mmi:bis", model4), multiline=T, rug = F, main = "", ylab= "ADHD symptoms", xlab ="Media Multitasking")

```

# 7. more on model visualizations:

what about viewing the actual fitted data points (instead of the regression lines) ?
Added Variable plots (or partial regression plot) allow us to look at the fitted data of our variable of interest, controlling for all of the other stuff in your model. 
```{r}

avPlot(model4, "bis")

# make it prettier!
avPlot(model4, "mmi", col = "Black", col.lines = "Blue", pch = 18, lwd= 3, 
       ylab =  "ADHD", xlab ="mmi",
       main = "Partial Regression Plot: ADHD by Media Multitasking")


```

if you want to really make beautiful graphs and customizations of your models, 
we encourage you to experiment with ggplot!

This was only a brief introduction to the statistical modeling world of R. There are many more options available: mixed-effects modeling, mediations, structural equation models, bayessian estimation.

# Data Challenge:
Now it's your turn! There are two data setsfor this challenge. One is data from a single subjects task performance across all trials (repeated measures). The second dataset consists of summary data from each subject on this task (between subjects).

```{r}

# 1. perform a paired sample t-test to test the effect of distractor number (NumDist) on dprime.

#2. Perform a t-test to determine whether there are differences in Dprime based on GroupStatus. (when distractor Number == 6 and confidence == hi)

#3. perform a linear regression to test the effects of media multitasking on Dprime 

```

# Bonus Data Challenge
Use lmer () to conduct a mixed-effects model of pria      ste test to analyze it. Use ggplot to plot the raw data & the fitted results of your model.

```{r}









```
