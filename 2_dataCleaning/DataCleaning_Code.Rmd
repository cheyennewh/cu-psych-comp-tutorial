---
title: "Getting your data ready for analysis"
author: "Ellen Tedeschi"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 5
---
## Goals of this lesson

Students will learn:
1. How to open various data types in R
2. How to check for missing or problematic data and address issues.
3. How to filter, rearrange and shape data in preparation for analysis. 

## Install Packages
Tidyverse is one package with many tools.  We will introduce you to this package in this lesson, and continue using tidyverse in the next module.

```{r}

library(tidyverse)

```


## Getting your Data into R

### Entering data directly

In some cases, you may want to enter data directly into R. This is easy with a small number of cases.

```{r}

# Direct Data Entry

score <- c(20, 16, 35, 19)

name <- c("Monica", "Michelle", "Paul", "Ellen")

year <- c(2, 5, 2, 1)

dataframe <- data.frame(name, score, year)

```


### Reading data into R

It's also easy to introduce errors this way, and with a lot of data it would get tedious. Most of the time, you'll be reading data from an external file (.txt of .csv), or opening up an existing dataset in R. Once you find the location of your files, what you do next will depend on the file format.

#### What's your working directory and where is the file you want?

Your working directory is the directory (and subdirectories) where the files you're working with are stored. If you opened this file from a .Rproj link, the folder where that link was located will automatically be your working directory. If not, you may need to change your working directory so that R can find files when you ask for them.

```{r}

getwd()

list.files()

#setwd("~/Desktop/R Tutorial/data_cleaning") 

```

#### What kind of file do you have?
```{r}

## For .txt, .csv and tab-deliminated files

?read.table

mydata <- read.table("Study1.csv")

# Add arguments to help R figure out how your data is organized

mydata <- read.table("Study1.csv", header=TRUE, sep=",", stringsAsFactors=FALSE)


# Other options include:
# read.csv, just like read.table but with better defaults for .csv
# read.delim, for when you have a separator that's not standard

## For getting data that's already in R-format

load("Study1.rda")


## For getting data from another program:
#install.packages("foreign")
#library(foreign)

#read.spss("<Path to file>")
#read.dta("<Path to file>")

```

Remember, all of these commands can have arguments that will help R make sense of your data. To find out what arguments are possible, put a question mark in front of the name of the function (e.g. ?read.table). For options not listed here, Google "<your data type> into R" and you should find instructions.

## Inspecting your data

Now you have data, time to get some results! But wait! Are you sure this data is ok? Doing some basic steps to inspect your data now can save you lots of headaches later, and R makes it really easy.

Start by checking that you have the expected number of rows and columns in your data frame. You can do this by looking at the Environment window, or by asking R.

### How is your data frame structured?
```{r}

# Number of rows and number of columns
nrow(mydata)
ncol(mydata)

# Names of columns
names(mydata)

# look at the first few rows
head(mydata, 10)


```

### Brief intro to tidyverse

Tidyverse is not one package, but instead it's multiple packages grouped together. They're all made by the same developers, so the functions play nicely together. If you've done any R before, there are some you're probably familiar with, like ggplot and dplyr, and others that are more obscure. These are all very useful packages, but they do have some tidyverse-specific syntax that we'll be using. (Note: the following paragraphs are an almost verbatim verision of what's in our standalone Tidyverse tutorial, written by Monica, which can be found on the github page)

Enter the pipe `%>%`! The pipe does one simple, but key, thing: **takes the object on the left-hand side and feeds it into the first argument of the function on the right-hand side.** This means that:

* `a %>% foo()` is equivalent to `foo(a)`. Fine and good
* `a %>% foo() %>% bar(arg = TRUE)` is equivalent to `bar(foo(a), arg = TRUE)`. Now, nested function calls read left-to-right!
* Most common use case: `df_new <- df_old %>% foo() %>% bar(arg = TRUE) %>% baz()` is equivalent to `df_new <- baz(bar(foo(df_old), arg = TRUE))`. Now, you can chain a series of preprocessing commands to operate on a dataframe all at once, and easily read those commands as typed in your script. No more accidentally not running some key preprocessing command that causes later code to break!

* take as their first argument the object to be operated upon
* return the same object (or an analog of said), but now operated upon

Essentially all functions from the tidyverse are pipe-safe, but bear this in mind when trying to incorporate functions from base R or other packages into your tidy new world.

### Rename a variable

We'll demonstrate the `%>%` command for our first cleaning step. Look back at your data frame.  What is that fifth variable? What does that even mean? Luckily, this is your study and you know that it's a personality questionnaire measuring neuroticism. Let's fix that using `recode()` from the `dplyr` package.

```{r}

# Simple command with no pipe, commented out so we don't run both.

#mydata <- rename(mydata, Neuroticism=Personality) ## NewVariableName = OldVariableName

# Simple command with pipe

mydata <- mydata %>% 
  rename(Neuroticism=Personality) 

```

It might seem like the first version is simpler, but it won't be once you start stacking functions together. For example, let's rearrange our variables (using `select()`) while also renameing the variables called T1, T2, T3, and T4. Note that we keep adding ` %>% ` between each function.

```{r}

mydata <- mydata %>% 
  rename(Day1 = T1, Day2 = T2, Day3 = T3, Day4 = T4) %>% 
  select(ID, Condition, Age, everything())
  
# using everything() within select() means you don't have to type all the variables out.

```

### Check for missing data

One problem you may have is missing data. Sometimes this is something you already know about, but you should check your data frame anyway to make sure nothing got missed in a data entry error. For small datasets, you can do this visually, but for larger ones you can ask R.

```{r}

# This command asks for rows that are not complete. 
mydata[!complete.cases(mydata),]

```

In this case, the missing value is the Age value in row 39. You know you have this info somewhere on a paper form, so you go dig it up and want to replace it.

```{r}

# Directly replace a missing value
mydata$Age[mydata$ID==39] <- 30

```

### Check for correct values

To look at some of the other variables, let's use the `table()` function. This works well for factors or variables with only a few different values. Our condition and sex variables are good here.
```{r}

# Make tables of categorical variables
table(mydata$Condition)

table(mydata$Sex)

```

When we look at the table for the Sex variable, we see another data entry problem. We have a third category that should really be another case of "Female". Here we are going to use the function `recode` from the `dplyr` package. 

```{r}


# Replace bad category label
mydata$Sex <- recode(mydata$Sex, Femle = "Female")

table(mydata$Sex)

```

Now let's look at the continuous variables. You can also look at these with the table function, but sometimes it's easier to visualize. The `hist()` function, which creates histograms, is good here.

```{r}
# Create histograms to see data distribution
hist(mydata$Age)
hist(mydata$Neuroticism)
```

Looks like we have a potential outlier on the neuroticism score. This could be an entry error, but it could also be a real value that just happens to be really low. This is why data inspection is so important for later analysis - now you know that value is there, it's up to you to decide how to deal with it.

### Filtering data 
Let's say we have decided aprori to exclude outliers 3SD above or below the mean. We will use the filter() function in tidyverse to clean the dataset.
```{r}
# mark upper and lower boundaries of data
# anything above upper or below lower will be excluded as outlier.
upper <- mean(mydata$Neuroticism) + 3*sd(mydata$Neuroticism)
lower <- mean(mydata$Neuroticism)- 3*sd(mydata$Neuroticism)

mydata <- mydata %>% 
  # only keep values within this range! 
  filter( Neuroticism > lower & Neuroticism < upper)

# check that we excluded 1 outlier. 
nrow(mydata)
hist(mydata$Neuroticism)
```

## Getting ready for analysis

Now that we've gone through and cleaned up the problems, you can think ahead to how you'll want to use this data. 

### Recoding variables

Sometimes we want to treat categorical variables as factors, but sometimes we want to pretend they're numeric (as in a regression, when binary variables can be coded as 0 and 1). Right now, Condition is coded as a binary numeric variable, but that's not very informative, so you'd rather have the values be descriptive. Here, the function `recode()` from the `dplyr` package is really useful again, but we're going to use a different version that will also turn the variable from numeric or factor data. We'll also create a second variable instead of overwriting Condition.

```{r}

# Transform into factor with labels using mutate () and recode_factor() 
mydata <- mydata %>%
  mutate(ConditionF =recode_factor(Condition, '0'='Control', '1'='Treatment'))

# check that your variable is now recoded as you'd like! 
summary(mydata$Condition)
```

### Calculating new variables

You may also want to recalculate or rescale some variables. For example, we can turn Neuroticism into a Z score, or calculate an average response across the four time points. For Z scores, you can use the `scale()` function. You can also use this to just mean-center the data.

```{r}

# calculate Z scores using mutate ()  and scale() 
mydata <- mydata %>%
  mutate(NeuroticismZ = scale(Neuroticism, center = TRUE, scale = TRUE))

hist(NeuroticismZ)

# one way to average multiple columns
# note that the additional `rowwise()` arguement is necessary, otherwise you will end up with a column of only the total average value of the four columns. `ungroup` undoes the `rowwise` command so that future arguments aren't automatically calculated rowwise.

mydata <- mydata %>% 
  rowwise() %>%
  mutate(Average = mean(c(T1, T2, T3, T4))) %>%
  ungroup()
                            

```

### Shaping data

Finally, you may want to change the layout of your data. Right now, our data frame is in "wide" format, which means that each row is a subject, and each observation gets its own column. For some analyses, you'll need to use "long" format, where each row is an observation, and columns specify things like time and ID to differentiate the observations. There are lots of packages that can handle data reshaping, but I'll show the `gather()` and `spread()` functions from `tidyr`.

```{r}

# Key is the name for the new column that will identify which observation it is, and value is the name for the new column that will have the actual values in it. In theory, you can name these whatever you want, but to keep everyone on the same page, name the key "Time" and the value "Score".

mydata_Long <- gather(mydata, key="Time", value="Score", T1:T4)


# Spread lets you go back the other direction. This should be identical to the original mydata 

mydata_Wide <- spread(mydata_Long, key="Time", value="Score")
```

## Saving your work

Once you've created a data cleaning script like this one, you'll have a record of all the edits you've made on the raw data, and you can recreate your cleaned data just by running the script again. However, it's often easier to save your cleaned data as its own file **(never overwrite the raw data)**, so when you come back to do analysis you don't have to bother with all the cleaning steps. 

You can always save data frames as a .csv for easy sharing and viewing outside of R.

```{r}

# Write data to a .csv
write.csv(mydata, file="Study1_Clean.csv")


```

However, you can also save in an R format that lets you save multiple variables/objects in the same file. For example, you might want to have a long and wide format, or one dataframe with all the data and one with just subject information. Saving as a .rda file allows you to save multiple objects at once for easy loading into R. You can also have the outputs of statistical models saved in these, along with their data.

```{r}

# Save a .rda. Add as many objects as you want, separated by commas
save(mydata_Long, mydata_Wide, file="Study1_clean.rda")


```

## Data Challenge!

Go to the file "CleaningChallenge_NoCode.Rmd" for your data challenge. This challenge will include skills from this tutorial, but it will also ask you to explore new functions we didn't cover. Remember to use the help command in R (?<function name>) and google as necessary. You'll also be using three files from "Study 2", so make sure they're in your folder: README_Study2.txt, Study2_Subjects.csv, and Study2_Trials.csv.

## Future Directions

Congratulations! You've now cleaned some data in R and you're ready to start working with your data. This tutorial only went over some basic cleaning steps, as you work with your own data, you may find yourself needing other tools. 

