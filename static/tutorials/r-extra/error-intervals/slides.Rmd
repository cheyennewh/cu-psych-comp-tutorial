---
title: "Presentation Ninja"
subtitle: "âš”<br/>with xaringan"
author: "Monica Thieu & Paul Bloom"
institute: "Dept of Psychology, Columbia University"
date: "2021-03-10 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    css: ["theme.css", "fonts.css"]
    lib_dir: libs
    nature:
      highlightLanguage: r
      highlightStyle: solarized-light
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
require(tidyverse)
require(magrittr)
library(tidybayes)
library(rstanarm)
source('https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R')
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo = FALSE, dev = "svglite")

se <- function (x, ...) {return (sd(x, ...)/sqrt(length(x)))}
```

# Outline

--

First, we'll review error intervals based on _how they're calculated._

--

Then, we'll explore different techniques for visualizing those intervals.

---

class: inverse, middle

# Two different types of error intervals

---

.pull-left[


## Analytical intervals

- calculated _exactly_ with **formulas**
- computationally _fast_
- _wholly_ reliant on distributional assumptions

]

.pull-right[

## Numerical intervals

- calculated _approximately_ over many **iterations**
- computationally _slower_
- _less_ reliant on distributional assumptions (and can work in the absence of assumptions!)

]

--

In the majority of cases, errors should agree when estimated using either method. In general, we recommend taking more time to estimate numerical intervals _unless:_

- You are confident that distributional assumptions will hold
- It is temporally/computationally infeasible to estimate numerical intervals

**Note:** one advantage to using numerical methods is that they will cause you to more carefully consider assumptions you can choose to make about your data & intermediate outputs

---

class: inverse, middle

## How can we be confident in our intervals? 

![yo_dawg_meme](https://memegenerator.net/img/instances/64796890.jpg)

---

# Analytical error intervals

--

- Ordinary least squares intervals

--

- Maximum likelihood intervals

---

## OLS intervals

This encompasses the parameter estimates and standard errors calculated from _ordinary least squares regressions._

--

Remember, OLS regressions capture a [variety](https://lindeloev.github.io/tests-as-linear/) of statistical scenarios (t-tests, correlations, ANOVAs, and more).

--

In general, the error intervals we can get from these tests are a **standard error of the parameter estimate** and its associated **confidence interval.**

--

These values are directly related to one another by the following general formula:

$$CI_p = \overline{T} \pm t_{crit} \times SE$$

--

In most cases, the distance from the test statistic to one CI bound is equal to the standard error times the critical value for the desired confidence level.

--

If we assume a 95% confidence interval, and that the sampling distribution of the test statistic is _t_-distributed or normally distributed, the CI is approximately equal to the test statistic $\pm$ 2 SEs.

---

Don't forget! Dr. Niall Bolger sez:

--

**Over many theoretical repeated runs of a study, N% of the N% confidence intervals for all runs of the study are expected to overlap with the true parameter.**

--

A single calculation of the N% confidence interval does _not_ reflect an N% probability that the true parameter lies within that interval.

--

So, _you can make a confidence interval, but you can't be confident in your interval_ - Dr. Niall Bolger


---

## ML intervals



Maximum likelihood models can fit multilevel data, or other data that cannot readily be modeled with ordinary least squares regression.

--

ML models, like those from `lme4`, produce standard errors by taking the second derivative of the parameter log-likelihood function with respect to the parameter of interest, $\theta$, at the value of the maximum-likelihood estimate of said parameter, $\hat{\theta}$.

--

When the log-likelihood function is estimated well, ML standard errors are a good approximation of the standard deviation of the sampling distribution for multilevel model coefficients.

--

However, if ML estimation _fails to converge_ on a set of parameter estimates, this may mean that the log-likelihood function _violates the assumptions needed_ to consider the SE a valid estimate.

--

See [Penn State STAT 504 Spring 2005 lecture slides](https://personal.psu.edu/abs12/stat504/Lecture/lec3_4up.pdf) for further reference.

---

## Drawbacks with Analytical Intervals: The "Mountain" Problem


OLS & ML estimation assume that paramters are normally distributed

--


Imagine estimating the contour of a mountain using two different strategies
  * Hiking up to the peak of a mountain & getting one measurement of the steepness of the slope on your way up
  * Putting on a blindfold and randomly walking around the mountain for days, repeatedly recording your height above sea level
  
--

<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/57/Multivariate_Gaussian.png/1024px-Multivariate_Gaussian.png" alt="drawing" width="500" height = "275"/>

---

## What if your mountain looks like this?

![non normal mountain 1](https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-319-27284-9_9/MediaObjects/393463_1_En_9_Fig1_HTML.gif)

---

## Or this?

![non normal mountain 1](https://miro.medium.com/max/1454/1*s1Uk0_3NY1DXrRWcb17QMQ.png)


---

class: inverse, middle

# Numerical intervals

--

- Bootstrapping

--

- Bayesian Monte Carlo sampling

---

## Bootstrapping

Randomly resample complete observations from the base dataset with replacement many times, calculating the test statistic once for every resample. Collate all estimates of the test statistic across bootstrap iterations into a sampling distribution.


![boostrap](https://yashuseth.files.wordpress.com/2017/12/bootstrap.png)


---

### Statistics you can bootstrap:

* You can bootstrap _basically any_ test statistic, no matter how complex
* Especially useful where the test statistic might not have a normal sampling distribution, and analytical intervals might be inappropriate.

  * Mean, median, standard deviation of a distribution
  * Regression coefficients
  * Prediction performance (accuracy, F1, AUC, R2)
  * Unsupervised learning (PCA, clustering)
  * Reliability (ICC) or intra-item consistency
  * Tree-based models (i.e. 'bagging' in a random forrest)
  
<img src="https://advstats.psychstat.org/book/images/bootstrap.svg" alt="drawing" width="800" height = "250"/>

---

## Bayesian Monte Carlo sampling

"Hiker + blindfold" 

<img src="https://mc-stan.org/images/feature/wide_ensemble.png" alt="drawing" width="800" height = "250"/>

--

* Similar to bootstrapping, can estimate _any test statistic_ with _any distribution_
* Can also incorporate _priors_
* With R or python, we commonly implement MCMC sampling using [Stan](https://mc-stan.org/) on the back end
  * Packages [brms](https://cran.r-project.org/web/packages/brms/index.html) and [rstanarm](https://cran.r-project.org/web/packages/rstanarm/index.html) allow us to do this for regressions using the same R syntax as `lm()` and `lmer()`

---

## Why use Bayesian Monte Carlo methods?

Analytical approaches _will_ fail you sooner or later
```
Warning messages:
1: In checkConv(attr(opt, "derivs"), optpar,ctrl=controlpar,ctrl=controlcheckConv, 
: unable to evaluate scaled gradient
2: In checkConv(attr(opt, "derivs"), optpar,ctrl=controlpar,ctrl=controlcheckConv, 
: Model failed to converge: degenerate Hessian with 1 negative eigenvalues
```

--

* Bayesian inference with weakly informative priors can keep estimates reasonable
* Especially for models with _many_ parameters like multilevel models, Bayesian priors + MCMC provide the constraints necessary
* telling the hiker "On the side of the mountain there most likely there isn't a 1-foot diameter pit that goes all the way to the center of the earth"
  
  
---


## Bayesian intervals: can you be confident in them?

* Yes! Bayesian models estimate $P(parameters|data)$
* So, intervals based on the model's posterior distribution can be thought of as intervals where "the model is N% sure that the true value of the parameter is"
* For this reason, hip & alternative Bayesians usually use phrases that aren't 'confidence intervals', like _Credible Intervals_ , _Posterior Intervals_, _Uncertainty Intervals_, or _Highest Posterior Density Interval (HPDI)_



---


class: inverse, middle

# Visualization

---

class: center, middle

The purpose of any graph, error bars or not, is to **make a comparison.** Error bars can serve that goal by making your comparison of interest as salient as possible.

---

# General best practices

---

## General best practices

When you can, show raw data beneath the summary points and error bars.

```{r}
# TODO: Simulate dataset with 2 between-subjects conditions (european-american vs asian-american), one DV (emotional expression), one sensible covariate (age?)
# Bias the data in some kind of way such that the covariate partially explains the DV
# Add a few outliers

random_age <- function (race) {
  
  # .2 (10-20) + .4 (20-30) + .3 (30-60) + .1 (60-80)
  
  if (race == "euro_am") {
    prob_breakdowns <- c(.2, .4, .3/3, .1/2)
  } else if (race == "as_am") {
    prob_breakdowns <- c(.2, .55, .2/3, .05/2)
  }
  
  tens <- sample(seq(10, 70, 10),
                 size = 1,
                 replace = TRUE,
                 prob = rep(prob_breakdowns, times = c(1, 1, 3, 2)))
  
  ones <- sample(0:9,
                 size = 1,
                 replace = TRUE)
  
  return (as.integer(tens + ones))
}

# This counts id from 1:n separately for the two races, so that number is the n per group
d <- crossing(id = 1:60, race = c("euro_am", "as_am")) %>% 
  mutate(age = map_int(race, random_age),
         age_scaled = (age-25)/10,
         race = factor(race, levels = c("euro_am", "as_am")),
         intercept = 0,
         beta_race = -0.5,
         beta_age = -0.15,
         emo = intercept + beta_race*(race == "as_am") + beta_age*age_scaled + rt(n(), df = 5))

```


.pull-left[

```{r, fig.height=7}
ggplot(d, aes(x = race, y = emo)) +
  stat_summary(color = 'red', fun.data = mean_cl_boot) +
  labs(y = 'Emotional Expression', title = 'Without raw data') +
  theme_bw()
```

]

.pull-right[

```{r, fig.height=7}
ggplot(d, aes(x = race, y = emo)) +
  geom_jitter(height = 0, width = .05) +
  stat_summary(color = 'red', fun.data = mean_cl_boot) +
  labs(y = 'Emotional Expression', title = 'With raw data') +
  theme_bw()
```

]

---

## General best practices

Use crossbars on the ends of error bars _thoughtfully,_ if at all.

--

Choose whether to show errors +- 1 SE, +-2 SE, 80% CI, 90%, 95% CI, 99% CI, or something else to _highlight the size of your effect of interest._

---

## General best practices

Where appropriate, choose error visualizations that highlight the density of the error distribution.






```{r, fig.height = 4}
dist = c(rnorm(n = 1000, mean = 0), rnorm(n = 500, mean = 5, sd = 4))
example_data = data.frame(dist)
example_data = mutate(example_data, group = rbinom(nrow(example_data), size = 1, prob = .5)) %>%
  mutate(group = ifelse(group == 1, 'Experiment', 'Control'))
example_data_summary = example_data %>%
  group_by(group) %>%
  summarise(median = quantile(dist, probs = 0.5),
            lwr_80 = quantile(dist, probs = .1),
            upr_80 = quantile(dist, probs = .9),
            lwr_99 = quantile(dist, probs = .005),
            upr_99 = quantile(dist, probs = .995)) 


ggplot(example_data, aes(x = dist)) +
  geom_histogram(bins = 50)


```


---

Error bars may lead people to view the data in a binary way. Specifically, error bars may lead people to treat the sampling distribution within the shown error bar as uniform and ignore the sampling distribution outside the error bar.

Error bars below show 80% and 99% intervals. 

--

.pull-left[

```{r}
ggplot(example_data_summary, aes(x = group, y = median, color = group)) +
  geom_errorbar(aes(ymin = lwr_80, ymax = upr_80),  width = 0, lwd = 3, alpha = .5) +
  geom_errorbar(aes(ymin = lwr_99, ymax = upr_99),  width = 0, lwd = 1, alpha = .5) +
  geom_point(size = 4) +
  theme_bw() +
  labs(y = 'Outcome') +
  theme(legend.position = 'none') +
  scale_color_brewer(palette = 'Set1')

```

]


.pull-right[

```{r}

ggplot(example_data_summary, aes(x = group, y = median, color = group)) +
  geom_errorbar(aes(ymin = lwr_80, ymax = upr_80),  width = 0, lwd = 3, alpha = .5) +
  geom_errorbar(aes(ymin = lwr_99, ymax = upr_99),  width = 0, lwd = 1, alpha = .5) +
  geom_point(size = 4) +
  geom_flat_violin(data = example_data, aes(x = group, y = dist, fill = group), 
                   position = position_nudge(.1),
                   alpha = .3) +
  theme_bw() +
  labs(y = 'Outcome') +
  theme(legend.position = 'none') +
  scale_color_brewer(palette = 'Set1') +
  scale_fill_brewer(palette = 'Set1')


```
]

---

## General best practices

For better or worse, _people tend to use error bars as a visual marker of statistical significance._ Try to **accommodate** this tendency while remaining faithful to your comparison of interest.

--

For example, when comparing a test statistic against a 0, show the CI. Accommodate the heuristic that "if the error bar clears 0, the results are 'significant'."

.pull-left[

```{r}
ggplot(d, aes(x = race, y = emo)) +
  geom_jitter(height = 0, width = .05) +
  stat_summary(color = 'red', fun.data = mean_cl_boot) +
  labs(y = 'Emotional Expression', title = 'Visualizing Each Group On Original Scale of The Data') +
  theme_bw()

```

]


```{r,results='hide'}
m_bayes = rstanarm::stan_glm(data = d, emo ~ race)
m_bayes_draws = as.data.frame(m_bayes)
m_bayes_draws_summary = m_bayes_draws %>%
  summarise(mean_est = mean(raceas_am),
            lwr_80 = quantile(raceas_am, probs = .1),
            upr_80 = quantile(raceas_am, probs = .9),
            lwr_99 = quantile(raceas_am, probs = .005),
            upr_99 = quantile(raceas_am, probs = .995)) 
```

.pull-right[

```{r}
ggplot(m_bayes_draws) +
  geom_vline(xintercept = 0, lty = 2, color = 'blue') +
  geom_density(aes(x = raceas_am), fill = 'purple', color = 'purple', alpha = .5) +
  geom_errorbarh(data = m_bayes_draws_summary, aes(y = 0, xmin = lwr_80, xmax = upr_80), height = 0, lwd = 2) +
  geom_errorbarh(data = m_bayes_draws_summary, aes(y = 0, xmin = lwr_99, xmax = upr_99), height = 0, lwd = 1) +
  geom_point(data = m_bayes_draws_summary, aes(y = 0, x = mean_est), size = 3) +
  theme_bw() +
  labs(x = 'Estimated Mean Difference In Emotional Expression\nAsian-American > European American', 
       y = 'Relative Density',
       title = 'Distribution for the effect of interest')
```

]

---
 
## Example: comparing two groups

* Here, we want to know whether emotional expression differs in our sample between European-American and Asian-American participant
* We'll use *regression* and generate uncertainty intervals for our parameters of interest


---



## Option 1: OLS regression with one binary predictor variable

* This method allows you to use the SE provided by `lm()` without having to worry about finding the correct formula. 
* It's quick, and you might already be familiar with `lm()` mdoel syntax
* Estimation might not be accurate if OLS assumptions aren't met
* We don't get as much detailed info on the uncertainty
* We get a *confidence* interval, so we can't be confident in it


---

## Option 1: OLS regression with one binary predictor variable

--
Run model

```
m_ols = lm(data = d, emo ~ race)
```
--


Get confidence intervals for the difference between groups
```
ols_interval_80 = confint(m_ols, 'raceas_am', level=0.80)
ols_interval_99 = confint(m_ols, 'raceas_am', level=0.99)
```

--

Get predictions for the mean of each group
```
prediction_grid= expand.grid(race = c('euro_am', 'as_am'))
prediction_frame_ols = predict(m_ols, newdata = prediction_grid, interval = 'confidence') %>%
  data.frame() %>% cbind(., prediction_grid)
```  
  
---


```{r, results='hide'}
m_ols = lm(data = d, emo ~ race)
summary(m_ols)

prediction_grid= expand.grid(race = c('euro_am', 'as_am'))
prediction_frame_ols = predict(m_ols, newdata = prediction_grid, interval = 'confidence') %>%
  data.frame() %>%
  cbind(., prediction_grid)

# for comparing the groups directly
ols_interval_80 = confint(m_ols, 'raceas_am', level=0.80)
ols_interval_99 = confint(m_ols, 'raceas_am', level=0.99)
ols_summary = data.frame(lwr_80 = ols_interval_80[1], 
                         upr_80 = ols_interval_80[2], 
                         lwr_99 = ols_interval_99[1],
                         upr_99 = ols_interval_99[2],
                         mean_est = m_ols$coefficients[2])

```


```{r, fig.height=5}
ols_a = ggplot(data = prediction_frame_ols, aes(x = race, y = fit, color = race)) +
  geom_point() +
  geom_hline(yintercept = 0, lty = 2) + 
  geom_jitter(data = d, aes(x = race, y = emo), height = 0, width = .05, alpha = .3) +
  geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0) +
  theme_bw() + 
  theme(legend.position = 'none') +
  scale_color_brewer(palette = 'Set1') +
  labs(x = '', y = 'Emotional Expression', title = 'Does not show key comparison')


ols_b = ggplot(ols_summary, aes(x = '', y = mean_est)) +
  geom_point() +
  geom_hline(yintercept = 0, lty = 2) + 
  geom_errorbar(aes(ymin = lwr_80, ymax = upr_80),  width = 0, lwd = 3, alpha = .5) +
  geom_errorbar(aes(ymin = lwr_99, ymax = upr_99),  width = 0, lwd = 1, alpha = .5) +
  theme_bw() +
  labs(x = '', y = 'Estimated Mean Difference In Emotional Expression\nAsian-American > European American', title = 'Shows key comparison')

cowplot::plot_grid(ols_a, ols_b)
```

---

## Option 2: Bootstrapping

Once we use numeric methods we have an additional bonus: access to the full sampling distribution for all parameters of interest

```
d_b <- d %>%
  rsample::bootstraps(times = 500) %>% rename(iteration = id) %>% 
  # rsample automatically labels the iterations as "Bootstrap%03d"
  # want these just to be integers pls
  mutate(iteration = as.integer(str_sub(iteration, start = -3L)),
         # rsample stores the splits as special "splits" objects
         # which don't take up the same amount of memory as a fully resampled dataframe
         # so you need to call as.data.frame on them before you run the model
         coefs_boot = map(splits, ~.x %>% as.data.frame() %>%
                            lm(emo ~ race * age_scaled, data = .) %>%
                            broom::tidy())) %>% 
  # drop the split objects, don't need the resampled data anymore
  select(-splits) %>% 
  # et voila, all your model parameters in a dataframe that's long by bootstrap iteration
  unnest(coefs_boot)
```

---


```{r}
d_b <- d %>%
  rsample::bootstraps(times = 500) %>%
  rename(iteration = id) %>% 
  # rsample automatically labels the iterations as "Bootstrap%03d"
  # want these just to be integers pls
  mutate(iteration = as.integer(str_sub(iteration, start = -3L)),
         # rsample stores the splits as special "splits" objects
         # which don't take up the same amount of memory as a fully resampled dataframe
         # so you need to call as.data.frame on them before you run the model
         coefs_boot = map(splits, ~.x %>%
                            as.data.frame() %>%
                            lm(emo ~ race, data = .) %>%
                            broom::tidy())) %>% 
  # drop the split objects, don't need the resampled data anymore
  select(-splits) %>% 
  # et voila, all your model parameters in a dataframe that's long by bootstrap iteration
  unnest(coefs_boot)
```

We really care about the `estimate` where `term == raceas_am`  here, but we could bootstrap any quantity we want

```{r}
head(d_b)
```


---

This full distribution of boostrapped estimates for the `raceas_am` term is really what we want

```
d_b %>%
  dplyr::filter(term == "raceas_am") %>%
  ggplot(data = ., aes(x = estimate)) +
  geom_histogram(bins = 50) +
  geom_vline(xintercept = 0) +
  labs(x = 'Bootstrapped estimates of the mean differerence in emotional expression\nAsian-American > European American', y = 'count') +
  theme_bw()
```


```{r, fig.height=2}
d_b %>%
  dplyr::filter(term == "raceas_am") %>%
  ggplot(data = ., aes(x = estimate)) +
  geom_histogram(bins = 50) +
  geom_vline(xintercept = 0, lty = 2) +
  labs(x = 'Bootstrapped estimates of the mean differerence in emotional expression\nAsian-American > European American', y = 'count') +
  theme_bw()
```

---

Summarizing the bootstrap distribution
```{r}
d_b_summary = d_b %>%
  dplyr::filter(term == "raceas_am") %>%
  summarise(mean_est = mean(estimate),
            lwr_80 = quantile(estimate, probs = .1),
            upr_80 = quantile(estimate, probs = .9),
            lwr_99 = quantile(estimate, probs = .005),
            upr_99 = quantile(estimate, probs = .995)) 
```

```
d_b_summary = d_b %>%
  dplyr::filter(term == "raceas_am") %>%
  summarise(mean_est = mean(estimate),
            lwr_80 = quantile(estimate, probs = .1),
            upr_80 = quantile(estimate, probs = .9),
            lwr_99 = quantile(estimate, probs = .005),
            upr_99 = quantile(estimate, probs = .995)) 
```

---

```{r, fig.height=5}
boot_b = ggplot(d_b_summary) +
  geom_hline(yintercept = 0, lty = 2, color = 'blue') +
  geom_flat_violin(data = dplyr::filter(d_b, term == 'raceas_am'),  aes(x = '', y = estimate), fill = 'purple', color = 'purple', alpha = .5) +
  geom_errorbar(data = d_b_summary, aes(x = '', ymin = lwr_80, ymax = upr_80), width = 0, lwd = 3, alpha = .5) +
  geom_errorbar(data = d_b_summary, aes(x = '', ymin = lwr_99, ymax = upr_99), width = 0, lwd = 1) +
  geom_point(data = d_b_summary, aes(x = '', y = mean_est), size = 3) +
  theme_bw() +
  labs(y = 'Estimated Mean Difference In Emotional Expression\nAsian-American > European American', 
       x = '', 
       title = 'Conf. Interval from Bootstrap')


get_plot_limits <- function(plot) {
    gb = ggplot_build(plot)
    xmin = gb$layout$panel_params[[1]]$x.range[1]
    xmax = gb$layout$panel_params[[1]]$x.range[2]
    ymin = gb$layout$panel_params[[1]]$y.range[1]
    ymax = gb$layout$panel_params[[1]]$y.range[2]
    list(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax)
}
lims_for_align = get_plot_limits(boot_b)


cowplot::plot_grid(ols_b + 
                     ylim(lims_for_align$ymin, lims_for_align$ymax) + labs(title = 'Conf. Interval from OLS'), 
                   boot_b +  ylim(lims_for_align$ymin, lims_for_align$ymax), 
                   align = 'h', axis = 'bt')
```

---

## Option 3: Bayesian regression

Run the Bayesian regression in `rstanarm` -- equivalent syntax to `lm()`
```
m_bayes = rstanarm::stan_glm(data = d, emo ~ race)
```
--

Extract posterior draws to a dataframe
```
m_bayes_draws = as.data.frame(m_bayes)
```

--

Inspect posterior draws
```{r}
head(m_bayes_draws)
```
---

Summarize posterior distribution

```
m_bayes_draws_summary = m_bayes_draws %>%
  summarise(mean_est = mean(raceas_am),
            lwr_80 = quantile(raceas_am, probs = .1),
            upr_80 = quantile(raceas_am, probs = .9),
            lwr_99 = quantile(raceas_am, probs = .005),
            upr_99 = quantile(raceas_am, probs = .995)) 
```
---

## Comparing analytical, bootstrap, and bayesian intervals

* In many settings, these methods will give similar results
* If there are discrepancies, _we almost always trust the numerical methods more_ 

```{r, fig.height=3}
d_b_summary$type = 'Bootstrap'
ols_summary$type = 'OLS'
m_bayes_draws_summary$type = 'Bayesian MCMC'

model_summaries = rbind(d_b_summary, ols_summary, m_bayes_draws_summary)


ggplot(model_summaries, aes(x = type, y= mean_est, color = type)) +
  geom_errorbar(aes(ymin = lwr_80, ymax = upr_80), width= 0, lwd = 2) +
  geom_errorbar(aes(ymin = lwr_99, ymax = upr_99), width= 0) +
  geom_point(size = 2, color = 'black') +
  labs(x = 'Interval Type', y = 'Estimated Mean Difference In Emotional Expression\nAsian-American > European American') +
  theme_bw() +
  theme(legend.position = 'none')


```
---

Only numerical methods will allow you to inspect the whole sampling distribution in detail though

```{r, fig.height = 5}
boot_bayes_full_dist = rbind(m_bayes_draws %>% dplyr::select(estimate = raceas_am) %>%
    mutate(type = 'Bayesian MCMC'), 
  d_b %>% dplyr::filter(term == 'raceas_am') %>% dplyr::select(estimate) %>%
    mutate(type = 'Bootstrap'))

dplyr::filter(model_summaries) %>%
  ggplot(data =., aes(x = type, y= mean_est, color = type)) +
  geom_errorbar(aes(ymin = lwr_80, ymax = upr_80), width= 0, lwd = 2) +
  geom_errorbar(aes(ymin = lwr_99, ymax = upr_99), width= 0) +
  geom_point(size = 2, color = 'black') +
  labs(x = 'Interval Type', y = 'Estimated Mean Difference In Emotional Expression\nAsian-American > European American') +
  theme_bw() +
  theme(legend.position = 'none') +
  geom_flat_violin(data = boot_bayes_full_dist, aes(x = type, y = estimate), position = position_nudge(.05)) 
```


---

## What about a continuous x variable?

Let's run another Bayesian model looking at emotional expression as a function of age

```{r, results='hide'}
mod_cont = rstanarm::stan_glm(emo ~ age, data = d)
age_grid = expand.grid(age = min(d$age):max(d$age))
age_predictions = tidybayes::linpred_draws(model = mod_cont, newdata = age_grid) %>%
  dplyr::select(-.chain, -.iteration)
```

```
mod_cont = rstanarm::stan_glm(emo ~ age, data = d)
```
--

Then we can get draws of the linear predictor with respect to age

```
age_grid = expand.grid(age = min(d$age):max(d$age))
age_predictions = tidybayes::linpred_draws(model = mod_cont, newdata = age_grid)
```

---

```{r}
head(age_predictions)
```

---


```{r}
age_prediction_summary = age_predictions %>%
  group_by(age) %>%
  summarise(mean_est = mean(.value),
            lwr_80 = quantile(.value, probs = .1),
            upr_80 = quantile(.value, probs = .9),
            lwr_99 = quantile(.value, probs = .005),
            upr_99 = quantile(.value, probs = .995)) 
```

.pull-left[

Spaghetti! 
```{r}
age_predictions %>%
  dplyr::filter(.draw < 500) %>%
  ggplot(data = ., aes(x = age, y = .value, group=.draw)) +
  geom_hline(yintercept = 0, lty = 2, color = 'red') +
  geom_line(alpha = .3) +
  theme_bw() +
  labs(x = 'Age (years)', y = 'Estimated Emotional Expression', title = 'Discrete Posterior Draws Represent Uncertainty') +
  geom_line(data = age_prediction_summary, aes(x = age, y = mean_est, group = NA), lwd = 2, color = 'purple')

```
]


.pull-right[

Ribbons! 
```{r}
ggplot(age_prediction_summary, aes(x = age, y = mean_est)) +
  geom_hline(yintercept = 0, lty = 2, color = 'red') +
  geom_line() +
  geom_ribbon(aes(ymin = lwr_80, ymax = upr_80), alpha = .3) +
  geom_ribbon(aes(ymin = lwr_99, ymax = upr_99), alpha = .2) +
  theme_bw() +
  labs(x = 'Age (years)', y = 'Estimated Emotional Expression', title = 'Ribbons for 80% and 99% uncertainty')
```

]

---

.pull-left[

Spaghetti + raw data! 
```{r}
age_predictions %>%
  dplyr::filter(.draw < 500) %>%
  ggplot(data = ., aes(x = age, y = .value, group=.draw)) +
  geom_hline(yintercept = 0, lty = 2, color = 'red') +
  geom_line(alpha = .3) +
  theme_bw() +
  labs(x = 'Age (years)', y = 'Estimated Emotional Expression', title = 'Discrete Posterior Draws Represent Uncertainty') +
  geom_line(data = age_prediction_summary, aes(x = age, y = mean_est, group = NA), lwd = 2, color = 'purple') +
  geom_point(data = d, aes(x = age, y = emo, group = NA), alpha = .5)

```
]


.pull-right[

Ribbons + raw data! 
```{r}
ggplot(age_prediction_summary, aes(x = age, y = mean_est)) +
  geom_hline(yintercept = 0, lty = 2, color = 'red') +
  geom_line() +
  geom_ribbon(aes(ymin = lwr_80, ymax = upr_80), alpha = .3) +
  geom_ribbon(aes(ymin = lwr_99, ymax = upr_99), alpha = .2) +
  theme_bw() +
  labs(x = 'Age (years)', y = 'Estimated Emotional Expression', title = 'Ribbons for 80% and 99% uncertainty') +
  geom_point(data = d, aes(x = age, y = emo, group = NA), alpha = .5)
```

]


---

## Discussion Points

* We *always* want to make sure we quantify uncertainty for the key comparison of interest
* It is also good to plot and quantify uncertainty from multiple angles (i.e. group means vs. difference)
* Visualizing your raw data helps you understand your uncertainty
* Numeric methods are almost always a good idea if feasible

---


## Code Implementation

We did *not* focus on the syntax behind working with these uncertainty intervals as much, but you can find all code for this presentation on the Columbia Psych Computing [Website](https://cu-psych-computing.github.io/cu-psych-comp-tutorial/tutorials/r-extra/) & [Github](https://github.com/cu-psych-computing/cu-psych-comp-tutorial/tree/master/static/tutorials/r-extra)



